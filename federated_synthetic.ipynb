{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066804f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import time\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "from itertools import islice\n",
    "from os import makedirs, path, getcwd\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_dataset, num_batches_per_epoch\n",
    "from options import args_parser\n",
    "from update import test_inference\n",
    "from models import get_model, get_optimizer\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from update import ClientShard, test_inference\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os import path, getcwd, makedirs\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, path.join(getcwd(), \"..\", \"..\"))\n",
    "\n",
    "from options import args_parser\n",
    "#from update import ClientShard, test_inference\n",
    "from models import get_model, VGG, CNNMnist\n",
    "from utils import (\n",
    "    get_dataset,\n",
    "    average_weights,\n",
    "    exp_details,\n",
    ")\n",
    "#Monai Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1e0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser('FL experiments parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e441f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='random seed', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=100,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--test_frac', type=float, default=0.1,\n",
    "                    help='the fraction of data to go into test split.')\n",
    "parser.add_argument('--frac', type=float, default=0.1,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=10,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "parser.add_argument('--local_bs', type=int, default=8,\n",
    "                    help=\"local batch size: B\")\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.5,\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--task', type=str, default='cv', help='task name')\n",
    "parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "parser.add_argument('--kernel_num', type=int, default=9,\n",
    "                    help='number of each kind of kernel')\n",
    "parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                    help='comma-separated kernel size to \\\n",
    "                    use for convolution')\n",
    "parser.add_argument('--num_channels', type=int, default=3, help=\"number \\\n",
    "                    of channels of imgs\")\n",
    "parser.add_argument('--norm', type=str, default='batch_norm',\n",
    "                    help=\"batch_norm, layer_norm, or None\")\n",
    "parser.add_argument('--num_filters', type=int, default=32,\n",
    "                    help=\"number of filters for conv nets -- 32 for \\\n",
    "                    mini-imagenet, 64 for omiglot.\")\n",
    "parser.add_argument('--max_pool', type=str, default='True',\n",
    "                    help=\"Whether use max pooling rather than \\\n",
    "                    strided convolutions\")\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='cifar', help=\"name \\\n",
    "                    of dataset\")\n",
    "parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
    "                    of classes\")\n",
    "parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "                    of optimizer\")\n",
    "parser.add_argument('--iid', type=int, default=1,\n",
    "                    help='Default set to IID. Set to 0 for non-IID.')\n",
    "parser.add_argument('--unequal', type=int, default=0,\n",
    "                    help='whether to use unequal data splits for  \\\n",
    "                    non-i.i.d setting (use 0 for equal splits)')\n",
    "parser.add_argument('--stopping_rounds', type=int, default=10,\n",
    "                    help='rounds of early stopping')\n",
    "parser.add_argument('--ROOT_DATA', type=str, default='./data/',\n",
    "                    help='Root data dyrectory ')\n",
    "\n",
    "parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b8d4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\"--task\", \"cv\", \"--dataset\", \"synthetic\", \"--epochs\", \"10\", \"--num_users\", \"2\", \n",
    "                          \"--ROOT_DATA\", \"/Users/sebastianotalora/work/postdoc/federated_learning/fedem/data/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3ff074",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  'cuda' if args.gpu else 'cpu'\n",
    "path_project = path.abspath('..')\n",
    "logger = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369f5a9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'num_users': 2, 'test_frac': 0.1, 'frac': 0.1, 'local_ep': 10, 'local_bs': 8, 'lr': 0.01, 'momentum': 0.5, 'task': 'cv', 'model': 'cnn', 'kernel_num': 9, 'kernel_sizes': '3,4,5', 'num_channels': 3, 'norm': 'batch_norm', 'num_filters': 32, 'max_pool': 'True', 'dataset': 'synthetic', 'num_classes': 10, 'gpu': None, 'optimizer': 'sgd', 'iid': 1, 'unequal': 0, 'stopping_rounds': 10, 'ROOT_DATA': '/Users/sebastianotalora/work/postdoc/federated_learning/fedem/data/', 'verbose': 1, 'seed': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575c445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading synthetic data...\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/data/train/synthetic/\n",
      "90 90\n",
      "10 10\n",
      "20 20\n",
      "Num users: 2\n",
      "{0: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]), 1: array([65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "       82, 83, 84, 85, 86, 87, 88, 89])}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "# Load monai segmentation model.\n",
    "global_model = get_model(args=args, img_size=train_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f03ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Task      : cv\n",
      "    Model     : cnn\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.01\n",
      "    Global Rounds   : 1\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    Fraction of users  : 0.1\n",
      "    Local Batch size   : 8\n",
      "    Local Epochs       : 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_details(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b4acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.local_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45aac0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations made with the following legths: \n",
      "Train: 20\n",
      "Valid: 20\n",
      "Test: 3\n",
      "Ratio Train: 8\n",
      "Ratio Valid: 1\n",
      "Ratio Test: 1\n",
      "| Global Round : 0 | Hidden client num : 0 | Local Epoch : 0 | [0/20 (0%)]\tLoss: 0.544326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 0 | Hidden client num : 0 | Local Epoch : 9 | [0/20 (0%)]\tLoss: 0.517002"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Load monai segmentation model.\n",
    "global_model = get_model(args=args, img_size=train_dataset[0][0].shape)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    local_weights, local_losses = [], []\n",
    "    global_model.train()\n",
    "    # Randomly sample a fraction of clients and retrieve their ids.\n",
    "    user_frac = max(int(args.frac * args.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(args.num_users), user_frac, replace=False)\n",
    "\n",
    "    for hidden_client_idx, idx in enumerate(idxs_users):\n",
    "        client_shard = ClientShard(args=args,\n",
    "                                   client_idx=hidden_client_idx,\n",
    "                                   dataset=train_dataset,\n",
    "                                   idxs=user_groups[idx],\n",
    "                                   logger=logger,\n",
    "                                   device=device)\n",
    "        updated_local_model, loss = client_shard.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(updated_local_model))\n",
    "        local_losses.append(copy.deepcopy(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0a284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
