{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066804f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import time\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "from itertools import islice\n",
    "from os import makedirs, path, getcwd\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_dataset, num_batches_per_epoch\n",
    "from options import args_parser\n",
    "from update import test_inference\n",
    "from models import get_model, get_optimizer\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from update import ClientShard, test_inference\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os import path, getcwd, makedirs\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, path.join(getcwd(), \"..\", \"..\"))\n",
    "\n",
    "from options import args_parser\n",
    "#from update import ClientShard, test_inference\n",
    "from models import get_model, VGG, CNNMnist\n",
    "from utils import (\n",
    "    get_dataset,\n",
    "    average_weights,\n",
    "    exp_details,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1e0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser('FL experiments parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e441f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='random seed', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=100,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--test_frac', type=float, default=0.1,\n",
    "                    help='the fraction of data to go into test split.')\n",
    "parser.add_argument('--frac', type=float, default=0.1,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=10,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "parser.add_argument('--local_bs', type=int, default=8,\n",
    "                    help=\"local batch size: B\")\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.5,\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--task', type=str, default='cv', help='task name')\n",
    "parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "parser.add_argument('--kernel_num', type=int, default=9,\n",
    "                    help='number of each kind of kernel')\n",
    "parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                    help='comma-separated kernel size to \\\n",
    "                    use for convolution')\n",
    "parser.add_argument('--num_channels', type=int, default=3, help=\"number \\\n",
    "                    of channels of imgs\")\n",
    "parser.add_argument('--norm', type=str, default='batch_norm',\n",
    "                    help=\"batch_norm, layer_norm, or None\")\n",
    "parser.add_argument('--num_filters', type=int, default=32,\n",
    "                    help=\"number of filters for conv nets -- 32 for \\\n",
    "                    mini-imagenet, 64 for omiglot.\")\n",
    "parser.add_argument('--max_pool', type=str, default='True',\n",
    "                    help=\"Whether use max pooling rather than \\\n",
    "                    strided convolutions\")\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='cifar', help=\"name \\\n",
    "                    of dataset\")\n",
    "parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
    "                    of classes\")\n",
    "parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "                    of optimizer\")\n",
    "parser.add_argument('--iid', type=int, default=1,\n",
    "                    help='Default set to IID. Set to 0 for non-IID.')\n",
    "parser.add_argument('--unequal', type=int, default=0,\n",
    "                    help='whether to use unequal data splits for  \\\n",
    "                    non-i.i.d setting (use 0 for equal splits)')\n",
    "parser.add_argument('--stopping_rounds', type=int, default=10,\n",
    "                    help='rounds of early stopping')\n",
    "parser.add_argument('--ROOT_DATA', type=str, default='./data/',\n",
    "                    help='Root data dyrectory ')\n",
    "\n",
    "parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8d4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\"--task\", \"cv\", \"--dataset\", \"synthetic\", \"--epochs\", \"2\", \"--num_users\", \"2\", \n",
    "                          \"--ROOT_DATA\", \"/Users/sebastianotalora/work/postdoc/federated_learning/fedem/data/\",\n",
    "                          \"--frac\", \"2\", \"--local_ep\", \"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e276b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  'cuda' if args.gpu else 'cpu'\n",
    "path_project = path.abspath('..')\n",
    "logger = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369f5a9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 2, 'num_users': 2, 'test_frac': 0.1, 'frac': 2.0, 'local_ep': 5, 'local_bs': 8, 'lr': 0.01, 'momentum': 0.5, 'task': 'cv', 'model': 'cnn', 'kernel_num': 9, 'kernel_sizes': '3,4,5', 'num_channels': 3, 'norm': 'batch_norm', 'num_filters': 32, 'max_pool': 'True', 'dataset': 'synthetic', 'num_classes': 10, 'gpu': None, 'optimizer': 'sgd', 'iid': 1, 'unequal': 0, 'stopping_rounds': 10, 'ROOT_DATA': '/Users/sebastianotalora/work/postdoc/federated_learning/fedem/data/', 'verbose': 1, 'seed': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575c445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading synthetic data...\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/data/train/synthetic/\n",
      "90 90\n",
      "10 10\n",
      "20 20\n",
      "Num users: 2\n",
      "{0: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]), 1: array([65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
      "       82, 83, 84, 85, 86, 87, 88, 89])}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "# Load monai segmentation model.\n",
    "global_model = get_model(args=args, img_size=train_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f03ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Task      : cv\n",
      "    Model     : cnn\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.01\n",
      "    Global Rounds   : 2\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    Fraction of users  : 2.0\n",
      "    Local Batch size   : 8\n",
      "    Local Epochs       : 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Start of Federated learning. {{{\n",
    "# Set the model to train and send it to device.\n",
    "global_model.to(device)\n",
    "global_model.train()\n",
    "#print(global_model)\n",
    "# copy weights\n",
    "global_weights = global_model.state_dict()\n",
    "# Training\n",
    "train_loss, train_accuracy = [], []\n",
    "print_every = 1\n",
    "exp_details(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beddd567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.local_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45aac0ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "| Global Round : 0 | Hidden client num : 0 | Local Epoch : 0 | [0/52 (0%)]\tLoss: 0.392104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 1 | Hidden client num : 1 | Local Epoch : 4 | [0/52 (0%)]\tLoss: 0.356468"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Load monai segmentation model.\n",
    "global_model = get_model(args=args, img_size=train_dataset[0][0].shape)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    local_weights, local_losses = [], []\n",
    "    global_model.train()\n",
    "    # Randomly sample a fraction of clients and retrieve their ids.\n",
    "    user_frac = 2#max(int(args.frac * args.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(args.num_users), user_frac, replace=False)\n",
    "\n",
    "    for hidden_client_idx, idx in enumerate(idxs_users):\n",
    "        client_shard = ClientShard(args=args,\n",
    "                                   client_idx=hidden_client_idx,\n",
    "                                   dataset=train_dataset,\n",
    "                                   idxs=user_groups[idx],\n",
    "                                   logger=logger,\n",
    "                                   device=device)\n",
    "        updated_local_model, loss = client_shard.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(updated_local_model))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "        \n",
    "    # Calculate averaged model weights from all the client trained models.\n",
    "    global_weights = average_weights(local_weights)\n",
    "    # Update global weights with the averaged model weights.\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    list_acc, list_loss = [], []\n",
    "    global_model.eval()\n",
    "    # Remove trained clients from heldout evaluation.\n",
    "    heldout_clients = list(range(args.num_users))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18a02c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: Hidden client num::   0%|                                                                                                    | 0/2 [00:00<?, ?it/s]/var/folders/3l/3j97gf9561z0v55nxnvw_0x40000gn/T/ipykernel_10746/2854325091.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "Evaluating: Hidden client num:: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 12.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for heldout_client_idx, idx in tqdm(enumerate(heldout_clients),\n",
    "                                        desc='Evaluating: Hidden client num:',\n",
    "                                        total=len(heldout_clients)):\n",
    "    client_shard = ClientShard(args=args,\n",
    "                                   client_idx=heldout_client_idx,\n",
    "                                   dataset=train_dataset,\n",
    "                                   idxs=user_groups[idx],\n",
    "                                   logger=logger,\n",
    "                                   device=device)\n",
    "    dice_client, loss = client_shard.inference(model=global_model)\n",
    "    list_loss.append(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb6fb2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6042181849479675, tensor(0.5417))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_client, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8952a9fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3l/3j97gf9561z0v55nxnvw_0x40000gn/T/ipykernel_10014/3032149967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mhidden_client_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for hidden_client_idx, idx in enumerate(idxs_users):\n",
    "    print(idxs_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1bd7128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9f39ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b98bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(args.num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_users = np.random.choice(range(args.num_users), user_frac, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8551c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(args.num_users), 2, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80caa731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce6f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
