{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57130cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.19.5\n",
      "Pytorch version: 1.10.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.7\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.7.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.11.1\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pandas version: 1.3.4\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "from itertools import islice\n",
    "from os import makedirs, path, getcwd\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_dataset, num_batches_per_epoch\n",
    "from options import args_parser\n",
    "from update import test_inference\n",
    "from models import get_model, get_optimizer\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from update import ClientShard, test_inference\n",
    "\n",
    "from tqdm import tqdm\n",
    "from os import path, getcwd, makedirs\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, path.join(getcwd(), \"..\", \"..\"))\n",
    "\n",
    "from options import args_parser\n",
    "#from update import ClientShard, test_inference\n",
    "from models import get_model, VGG, CNNMnist\n",
    "from utils import (\n",
    "    get_dataset,\n",
    "    average_weights,\n",
    "    exp_details,\n",
    ")\n",
    "\n",
    "#MONAI Imports\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import DataLoader, decollate_batch,ArrayDataset, GridPatchDataset\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import SegResNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    AsChannelFirst,\n",
    "    Compose,\n",
    "    ConvertToMultiChannelBasedOnBratsClassesd,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    LabelToMask,\n",
    "    LoadImage,\n",
    "    MapTransform,\n",
    "    NormalizeIntensity,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    RandSpatialCrop,\n",
    "    Resize,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    Spacing,\n",
    "    Spacingd,\n",
    "    ScaleIntensity, \n",
    "    SpatialCrop,\n",
    "    ToTensor,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Resized\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "from natsort import natsorted\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "import os.path\n",
    "import nibabel as nib\n",
    "from nibabel import load, save, Nifti1Image\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de17ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser('FL experiments parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90bece4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='random seed', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# federated arguments (Notation for the arguments followed from paper)\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help=\"number of rounds of training\")\n",
    "parser.add_argument('--num_users', type=int, default=100,\n",
    "                    help=\"number of users: K\")\n",
    "parser.add_argument('--test_frac', type=float, default=0.1,\n",
    "                    help='the fraction of data to go into test split.')\n",
    "parser.add_argument('--frac', type=float, default=0.1,\n",
    "                    help='the fraction of clients: C')\n",
    "parser.add_argument('--local_ep', type=int, default=10,\n",
    "                    help=\"the number of local epochs: E\")\n",
    "parser.add_argument('--local_bs', type=int, default=8,\n",
    "                    help=\"local batch size: B\")\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.5,\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--task', type=str, default='cv', help='task name')\n",
    "parser.add_argument('--model', type=str, default='cnn', help='model name')\n",
    "parser.add_argument('--kernel_num', type=int, default=9,\n",
    "                    help='number of each kind of kernel')\n",
    "parser.add_argument('--kernel_sizes', type=str, default='3,4,5',\n",
    "                    help='comma-separated kernel size to \\\n",
    "                    use for convolution')\n",
    "parser.add_argument('--num_channels', type=int, default=3, help=\"number \\\n",
    "                    of channels of imgs\")\n",
    "parser.add_argument('--norm', type=str, default='batch_norm',\n",
    "                    help=\"batch_norm, layer_norm, or None\")\n",
    "parser.add_argument('--num_filters', type=int, default=32,\n",
    "                    help=\"number of filters for conv nets -- 32 for \\\n",
    "                    mini-imagenet, 64 for omiglot.\")\n",
    "parser.add_argument('--max_pool', type=str, default='True',\n",
    "                    help=\"Whether use max pooling rather than \\\n",
    "                    strided convolutions\")\n",
    "\n",
    "# other arguments\n",
    "parser.add_argument('--dataset', type=str, default='cifar', help=\"name \\\n",
    "                    of dataset\")\n",
    "parser.add_argument('--num_classes', type=int, default=10, help=\"number \\\n",
    "                    of classes\")\n",
    "parser.add_argument('--gpu', default=None, help=\"To use cuda, set \\\n",
    "                    to a specific GPU ID. Default set to use CPU.\")\n",
    "parser.add_argument('--optimizer', type=str, default='sgd', help=\"type \\\n",
    "                    of optimizer\")\n",
    "parser.add_argument('--iid', type=int, default=1,\n",
    "                    help='Default set to IID. Set to 0 for non-IID.')\n",
    "parser.add_argument('--unequal', type=int, default=0,\n",
    "                    help='whether to use unequal data splits for  \\\n",
    "                    non-i.i.d setting (use 0 for equal splits)')\n",
    "parser.add_argument('--stopping_rounds', type=int, default=10,\n",
    "                    help='rounds of early stopping')\n",
    "parser.add_argument('--ROOT_DATA', type=str, default='./data/',\n",
    "                    help='Root data dyrectory ')\n",
    "\n",
    "parser.add_argument('--verbose', type=int, default=1, help='verbose')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8edee9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIEU = 'sebastian_laptop'\n",
    "\n",
    "if LIEU=='sebastian_insel':\n",
    "    root_exp  = '/home/sebastian/experiments/fedem/'\n",
    "    root_data = '/media/sebastian/data/ASAP/BRATS_2019_ubelix/center_wise/'\n",
    "    brats_nifti__dir_paths = natsorted(glob(root_data+\"**/**/\"))\n",
    "\n",
    "if LIEU=='sebastian_laptop':\n",
    "    root_exp  = '/Users/sebastianotalora/work/postdoc/federated_learning/fedem/'\n",
    "    root_data = '/Users/sebastianotalora/work/postdoc/federated_learning/data/'\n",
    "    brats_nifti__dir_paths = natsorted(glob(root_data+'brats/'\"**/**/\"))\n",
    "len(brats_nifti__dir_paths)#Should be 259\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334d96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\"--task\", \"cv\", \"--dataset\", \"brats\", \"--epochs\", \"2\", \"--num_users\", \"4\", \n",
    "                          \"--ROOT_DATA\", root_data,\n",
    "                          \"--frac\", \"2\", \"--local_ep\", \"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694e95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  'cuda' if args.gpu else 'cpu'\n",
    "path_project = path.abspath('..')\n",
    "logger = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8c9a64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 2, 'num_users': 4, 'test_frac': 0.1, 'frac': 2.0, 'local_ep': 5, 'local_bs': 8, 'lr': 0.01, 'momentum': 0.5, 'task': 'cv', 'model': 'cnn', 'kernel_num': 9, 'kernel_sizes': '3,4,5', 'num_channels': 3, 'norm': 'batch_norm', 'num_filters': 32, 'max_pool': 'True', 'dataset': 'brats', 'num_classes': 10, 'gpu': None, 'optimizer': 'sgd', 'iid': 1, 'unequal': 0, 'stopping_rounds': 10, 'ROOT_DATA': '/Users/sebastianotalora/work/postdoc/federated_learning/data/', 'verbose': 1, 'seed': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f189b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n",
      "loading BraTS data from /Users/sebastianotalora/work/postdoc/federated_learning/data/brats/\n",
      "180 28 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BraTS segmentation Network\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_dataset, test_dataset, user_groups = get_dataset(args)\n",
    "\n",
    "# Load monai segmentation model.\n",
    "global_model = get_model(args=args, img_size=train_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b4baac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(epochs=2, num_users=4, test_frac=0.1, frac=2.0, local_ep=5, local_bs=8, lr=0.01, momentum=0.5, task='cv', model='cnn', kernel_num=9, kernel_sizes='3,4,5', num_channels=3, norm='batch_norm', num_filters=32, max_pool='True', dataset='brats', num_classes=10, gpu=None, optimizer='sgd', iid=1, unequal=0, stopping_rounds=10, ROOT_DATA='/Users/sebastianotalora/work/postdoc/federated_learning/data/', verbose=1, seed=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26dc1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ac3f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegResNet(\n",
       "  (act): ReLU(inplace=True)\n",
       "  (convInit): Convolution(\n",
       "    (conv): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (down_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock(\n",
       "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv1): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "        (conv2): Convolution(\n",
       "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_samples): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Convolution(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (1): UpSample(\n",
       "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_final): Sequential(\n",
       "    (0): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Convolution(\n",
       "      (conv): Conv3d(16, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout3d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0274fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Task      : cv\n",
      "    Model     : cnn\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.01\n",
      "    Global Rounds   : 2\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    Fraction of users  : 2.0\n",
      "    Local Batch size   : 8\n",
      "    Local Epochs       : 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Start of Federated learning. {{{\n",
    "# Set the model to train and send it to device.\n",
    "global_model.to(device)\n",
    "global_model.train()\n",
    "#print(global_model)\n",
    "# copy weights\n",
    "global_weights = global_model.state_dict()\n",
    "# Training\n",
    "train_loss, train_dice = [], []\n",
    "print_every = 1\n",
    "exp_details(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0386c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.local_bs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b1f63af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.local_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f22cb3a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BraTS segmentation Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/transforms/post/array.py:182: UserWarning: `threshold_values=True/False` is deprecated, please use `threshold=value` instead.\n",
      "  warnings.warn(\"`threshold_values=True/False` is deprecated, please use `threshold=value` instead.\")\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "| Global Round : 0 | Hidden client num : 0 | Local Epoch : 0 | [0/65 (0%)]\tLoss: 0.991118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "| Global Round : 0 | Hidden client num : 0 | Local Epoch : 0 | [10/65 (15%)]\tLoss: 0.976250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n",
      "/opt/anaconda3/envs/fed/lib/python3.9/site-packages/monai/data/utils.py:532: UserWarning: Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  warnings.warn(f\"Modifying image pixdim from {pixdim} to {norm}\")\n",
      "/Users/sebastianotalora/work/postdoc/federated_learning/fedem/update.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(content), torch.tensor(label)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3l/3j97gf9561z0v55nxnvw_0x40000gn/T/ipykernel_1493/1398422086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                    \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                    device=device)\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mupdated_local_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_shard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlocal_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_local_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlocal_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/postdoc/federated_learning/fedem/update.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, model, global_round)\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fed/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/fed/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Load monai segmentation model.\n",
    "global_model = get_model(args=args, img_size=train_dataset[0][0].shape)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    local_weights, local_losses = [], []\n",
    "    global_model.train()\n",
    "    # Randomly sample a fraction of clients and retrieve their ids.\n",
    "    user_frac = 2#max(int(args.frac * args.num_users), 1)\n",
    "    idxs_users = np.random.choice(range(args.num_users), user_frac, replace=False)\n",
    "\n",
    "    for hidden_client_idx, idx in enumerate(idxs_users):\n",
    "        client_shard = ClientShard(args=args,\n",
    "                                   client_idx=hidden_client_idx,\n",
    "                                   dataset=train_dataset,\n",
    "                                   idxs=user_groups[idx],\n",
    "                                   logger=logger,\n",
    "                                   device=device)\n",
    "        updated_local_model, loss = client_shard.update_weights(model=copy.deepcopy(global_model), global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(updated_local_model))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "        \n",
    "    # Calculate averaged model weights from all the client trained models.\n",
    "    global_weights = average_weights(local_weights)\n",
    "    # Update global weights with the averaged model weights.\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)    \n",
    "    \n",
    "    # Calculate avg training accuracy over all users at every epoch\n",
    "    list_dice, list_loss = [], []\n",
    "    global_model.eval()\n",
    "    # Remove trained clients from heldout evaluation.\n",
    "    heldout_clients = list(range(args.num_users))#In the 2-centers information we can not take one of them...\n",
    "    #for train_client_idx in list(idxs_users):\n",
    "    #    heldout_clients.remove(train_client_idx)\n",
    "    ###\n",
    "    for heldout_client_idx, idx in tqdm(enumerate(heldout_clients),\n",
    "                                        desc='Evaluating: Hidden client num:',\n",
    "                                        total=len(heldout_clients)):\n",
    "        client_shard = ClientShard(args=args,\n",
    "                                   client_idx=heldout_client_idx,\n",
    "                                   dataset=train_dataset,\n",
    "                                   idxs=user_groups[idx],\n",
    "                                   logger=logger,\n",
    "                                   device=device)\n",
    "        loss, dice_client = client_shard.inference(model=global_model)\n",
    "        list_dice.append(dice_client)\n",
    "        list_loss.append(loss)\n",
    "    train_dice.append(sum(list_dice) / len(list_dice))\n",
    "    ###\n",
    "    # print global training loss after every 'i' rounds\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        print(f' \\nAvg Training Stats after {epoch + 1} global rounds:')\n",
    "        print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "        print('Train DICE: {:.2f}% \\n'.format(100 * train_dice[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference after completion of training\n",
    "test_dice, test_loss = test_inference(args=args, model=global_model, test_dataset=test_dataset, device=device)\n",
    "\n",
    "print(f' \\n Results after {args.epochs} global rounds of training:')\n",
    "print(\"|---- Avg Train DICE: {:.2f}%\".format(100*train_dice[-1]))\n",
    "print(\"|---- Test DICE: {:.2f}%\".format(100*test_dice))\n",
    "### }}} End of Federated learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a0be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
